{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICTING HOUSE PRICES USING MULTIPLE LINEAR REGRESSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, make_scorer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from math import sqrt, log, exp\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 81)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train= pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "# adding SalePrice column to test dataset for consistency\n",
    "test['SalePrice'] = 0\n",
    "frames = [train, test]\n",
    "df = pd.concat(frames)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing_data(df):\n",
    "    # Create a DataFrame of all features with the correspnding number of missing values     \n",
    "    missing = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_df = pd.DataFrame(missing, columns = ['Missing'])\n",
    "    missing_table = missing_df[missing_df.Missing > 0]\n",
    "    \n",
    "    # Drop Features with more than 500 missing values\n",
    "    df = df.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],axis=1)\n",
    "    missing_table = missing_table.drop(['PoolQC','MiscFeature','Alley','Fence','FireplaceQu'],axis=0)\n",
    "    \n",
    "    # I found out that some numerical features are actually really categories, after going through kaggle user juliencs' notebook\n",
    "    # https://www.kaggle.com/juliencs/a-study-on-regression-applied-to-the-ames-dataset\n",
    "\n",
    "    df = df.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", 50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                                     80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", 150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "                     \"MoSold\"     : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                                     7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"}})\n",
    "    \n",
    "    # Convert the new categories feature to type category.  \n",
    "    df['MSSubClass'] = df['MSSubClass'].astype('category')\n",
    "    df['MoSold'] = df['MoSold'].astype('category')\n",
    "    \n",
    "    # Seperate the numerical missing features from non-numeric ones.    \n",
    "    numeric = []\n",
    "    non_numeric = []\n",
    "    for missing in missing_table.index:\n",
    "        if df[missing].dtype == np.object:\n",
    "            non_numeric.append(missing)\n",
    "        else:\n",
    "            numeric.append(missing)\n",
    "    \n",
    "    # Fill all missing numeric features with O except for 'LotFrontage' feature which we replace with the mean.\n",
    "    for feature in numeric:\n",
    "        if feature != 'LotFrontage':\n",
    "            df[feature] = df[feature].fillna(0)\n",
    "        else:\n",
    "            df['LotFrontage'] = df['LotFrontage'].fillna(df['LotFrontage'].mean())\n",
    "        \n",
    "    # Fill all missing non-numeric features with 'NA' and 'None' appropiately.     \n",
    "    fill_with_no = [\"BsmtQual\",\"BsmtCond\",\"BsmtExposure\",\"BsmtFinType1\",\"BsmtFinType2\",\"GarageType\",\"GarageFinish\",\"GarageQual\",\"GarageCond\"]\n",
    "    for feature in fill_with_no:\n",
    "        df[feature] = df[feature].fillna(\"NA\")\n",
    "    \n",
    "    df[\"MasVnrType\"] = df[\"MasVnrType\"].fillna(\"None\")\n",
    "    \n",
    "    # No Absent Value for some features, so we'll go ahead to use the mode to replace all Nil values\n",
    "    fill_with_mode = [\"MSZoning\",\"Utilities\",\"Functional\",\"Exterior1st\",\"KitchenQual\",\"Exterior2nd\",\"SaleType\",\"Electrical\",\"MSSubClass\",\"MoSold\"]\n",
    "    for feature in fill_with_mode:\n",
    "        df[feature] = df[feature].fillna(df[feature].mode().iloc[0])\n",
    "    \n",
    "    # Final check for missing data\n",
    "    if df.isnull().values.any():\n",
    "        return 'There are still some missing values'\n",
    "    else:\n",
    "        return \"There are no more missing values\",df\n",
    "\n",
    "def ordinal_categorical(df):\n",
    "    # Converting Ordinal Variables into a numerical scale\n",
    "\n",
    "    ordered_lotshape = ['IR3','IR2','IR1','Reg']\n",
    "    df['LotShape'] = df['LotShape'].astype(\"category\",ordered=True,categories=ordered_lotshape).cat.codes\n",
    "\n",
    "    ordered_landcontour = ['Low','HLS','Bnk','Lvl']\n",
    "    df['LandContour'] = df['LandContour'].astype(\"category\",ordered=True,categories=ordered_landcontour).cat.codes\n",
    "\n",
    "    ordered_exterqual = ['Po','Fa','TA','Gd','Ex']\n",
    "    df['ExterQual'] = df['ExterQual'].astype(\"category\",ordered=True,categories=ordered_exterqual).cat.codes\n",
    "\n",
    "    ordered_extercond = ['Po','Fa','TA','Gd','Ex']\n",
    "    df['ExterCond'] = df['ExterCond'].astype(\"category\",ordered=True,categories=ordered_extercond).cat.codes\n",
    "\n",
    "    ordered_bsmtqual = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "    df['BsmtQual'] = df['BsmtQual'].astype(\"category\",ordered=True,categories=ordered_bsmtqual).cat.codes\n",
    "\n",
    "    ordered_bsmtcond = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "    df['BsmtCond'] = df['BsmtCond'].astype(\"category\",ordered=True,categories=ordered_bsmtcond).cat.codes\n",
    "\n",
    "    ordered_bsmtexposure = ['NA','No','Mn','Av','Gd']\n",
    "    df['BsmtExposure'] = df['BsmtExposure'].astype(\"category\",ordered=True,categories=ordered_bsmtexposure).cat.codes\n",
    "\n",
    "    ordered_bsmtfintype1 = ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ']\n",
    "    df['BsmtFinType1'] = df['BsmtFinType1'].astype(\"category\",ordered=True,categories=ordered_bsmtfintype1).cat.codes\n",
    "\n",
    "    ordered_bsmtfintype2 = ['NA','Unf','LwQ','Rec','BLQ','ALQ','GLQ']\n",
    "    df['BsmtFinType2'] = df['BsmtFinType2'].astype(\"category\",ordered=True,categories=ordered_bsmtfintype2).cat.codes\n",
    "\n",
    "    ordered_heatingqc = ['Po','Fa','TA','Gd','Ex']\n",
    "    df['HeatingQC'] = df['HeatingQC'].astype(\"category\",ordered=True,categories=ordered_heatingqc).cat.codes\n",
    "\n",
    "    ordered_kitchenqual = ['Po','Fa','TA','Gd','Ex']\n",
    "    df['KitchenQual'] = df['KitchenQual'].astype(\"category\",ordered=True,categories=ordered_kitchenqual).cat.codes\n",
    "\n",
    "    ordered_functional = ['Sal','Sev','Maj1','Maj2','Mod','Min2','Min1','Typ']\n",
    "    df['Functional'] = df['Functional'].astype(\"category\",ordered=True,categories=ordered_functional).cat.codes\n",
    "\n",
    "    ordered_garagefinish = ['NA','Unf','RFn','Fin']\n",
    "    df['GarageFinish'] = df['GarageFinish'].astype(\"category\",ordered=True,categories=ordered_garagefinish).cat.codes\n",
    "\n",
    "    ordered_garagequal = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "    df['GarageQual'] = df['GarageQual'].astype(\"category\",ordered=True,categories=ordered_garagequal).cat.codes\n",
    "\n",
    "    ordered_garagecond = ['NA','Po','Fa','TA','Gd','Ex']\n",
    "    df['GarageCond'] = df['GarageCond'].astype(\"category\",ordered=True,categories=ordered_garagecond).cat.codes\n",
    "\n",
    "    ordered_utilities = ['ELO','NoSeWa','NoSewr','AllPub']\n",
    "    df['Utilities'] = df['Utilities'].astype(\"category\",ordered=True,categories=ordered_utilities).cat.codes\n",
    "\n",
    "    ordered_landslope = ['Sev','Mod','Gtl']\n",
    "    df['LandSlope'] = df['LandSlope'].astype(\"category\",ordered=True,categories=ordered_landslope).cat.codes\n",
    "\n",
    "    ordered_electrical = ['Mix','FuseP','FuseF','FuseA','SBrkr']\n",
    "    df['Electrical'] = df['Electrical'].astype(\"category\",ordered=True,categories=ordered_electrical).cat.codes\n",
    "\n",
    "    ordered_paveddrive = ['N','P','Y']\n",
    "    df['PavedDrive'] = df['PavedDrive'].astype(\"category\",ordered=True,categories=ordered_paveddrive).cat.codes\n",
    "    \n",
    "    ordinal = ['Utilities','LandSlope','Electrical','LotShape','PavedDrive','LandContour','ExterQual','GarageCond','ExterCond','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2','HeatingQC','KitchenQual','Functional','GarageFinish','GarageQual']\n",
    "    ordinal_scale = {}\n",
    "    for var in ordinal:\n",
    "        ordinal_scale[var] = df[var].unique()\n",
    "    \n",
    "    return ordinal_scale\n",
    "\n",
    "def log_rmse(model, X, y):\n",
    "    '''\n",
    "    The evaluation metric for this problem is Root-Mean-Squared-Error (RMSE) between the logarithm\n",
    "    of the predicted value and the logarithm of the observed sales price. Since we already log transformed y\n",
    "    earlier we compute the RMSE as it is.\n",
    "    \n",
    "    '''   \n",
    "    # Fit model on X & y inp     \n",
    "    model.fit(X,y)\n",
    "    prediction = model.predict(X)\n",
    "    \n",
    "    return sqrt(mean_squared_error((y), prediction))\n",
    "\n",
    "def generate_submission(test,model,submission_name):\n",
    "    test_prediction = model.predict(test)\n",
    "    test_pred = pd.DataFrame(abs(np.exp(test_prediction)))\n",
    "    ID = pd.DataFrame(test['Id'])\n",
    "    pred = ID.join(test_pred)\n",
    "    submission_file = submission_name + '.csv'\n",
    "    pred.to_csv(submission_file, header=['Id','SalePrice'],index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ## 1. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.1 Deal with missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no more missing values\n"
     ]
    }
   ],
   "source": [
    "# Run our predefined function that deals with missing data and returns a result variable & a clean dataset void of missing values. \n",
    "result, clean_data = missing_data(df)\n",
    "\n",
    "# Print result of the missing_data function\n",
    "print result\n",
    "\n",
    "# Assign clean_data to df\n",
    "df =  clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### 1.2 Convert ordinal variables into a numerical scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BsmtCond': array([3, 4, 0, 2, 1], dtype=int64),\n",
       " 'BsmtExposure': array([1, 4, 2, 3, 0], dtype=int64),\n",
       " 'BsmtFinType1': array([6, 5, 1, 3, 4, 0, 2], dtype=int64),\n",
       " 'BsmtFinType2': array([1, 4, 0, 5, 3, 2, 6], dtype=int64),\n",
       " 'BsmtQual': array([4, 3, 5, 0, 2], dtype=int64),\n",
       " 'Electrical': array([4, 2, 3, 1, 0], dtype=int64),\n",
       " 'ExterCond': array([2, 3, 1, 0, 4], dtype=int64),\n",
       " 'ExterQual': array([3, 2, 4, 1], dtype=int64),\n",
       " 'Functional': array([7, 6, 2, 5, 4, 3, 1], dtype=int64),\n",
       " 'GarageCond': array([3, 2, 0, 4, 1, 5], dtype=int64),\n",
       " 'GarageFinish': array([2, 1, 3, 0], dtype=int64),\n",
       " 'GarageQual': array([3, 2, 4, 0, 5, 1], dtype=int64),\n",
       " 'HeatingQC': array([4, 3, 2, 1, 0], dtype=int64),\n",
       " 'KitchenQual': array([3, 2, 4, 1], dtype=int64),\n",
       " 'LandContour': array([3, 2, 0, 1], dtype=int64),\n",
       " 'LandSlope': array([2, 1, 0], dtype=int64),\n",
       " 'LotShape': array([3, 2, 1, 0], dtype=int64),\n",
       " 'PavedDrive': array([2, 0, 1], dtype=int64),\n",
       " 'Utilities': array([3, 1], dtype=int64)}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale = ordinal_categorical(df)\n",
    "scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Paper for this dataset the author pointed out a pitfall;\n",
    "\n",
    "\n",
    "> Potential Pitfalls (Outliers): Although all known errors were corrected in the data, no observations have been removed due to unusual values and all final residential sales from the initial data set are included in the data presented with this article. There are five observations that an instructor may wish to remove from the data set before giving it to students (a plot of SALE PRICE versus GR LIV AREA will quickly indicate these points). Three of them are true outliers (Partial Sales that likely don’t represent actual market values) and two of them are simply unusual sales (very large houses priced relatively appropriately). **I would recommend removing any houses with more than 4000 square feet from the data set (which eliminates these five unusual observations) before assigning it to students.**  \n",
    "\n",
    "So we go ahead to delete all observations with GrlivArea above 4000ft."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 76)\n",
      "(1459, 76)\n",
      "(2915, 76)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# From our combined we get back our train & test datasets\n",
    "train = df[:1460]\n",
    "test = df[1460:]\n",
    "\n",
    "# Drop all rows in the train dataset with 'GrLivArea' greater than 4000\n",
    "train = train.drop(train[train['GrLivArea'] >= 4000].index,axis=0)\n",
    "\n",
    "# New shape of train data after removing outliers\n",
    "print train.shape\n",
    "print test.shape\n",
    "\n",
    "# Combine train and test so we can continue performing other operations on the whole dataset\n",
    "frames = [train, test]\n",
    "df = pd.concat(frames)\n",
    "print df.shape\n",
    "\n",
    "# Make sure there is no null value in the target feature\n",
    "np.where(np.isnan(df['SalePrice']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SC60</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.221314</td>\n",
       "      <td>-0.202770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0.700717</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.026216</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359882</td>\n",
       "      <td>-0.116501</td>\n",
       "      <td>-0.270606</td>\n",
       "      <td>-0.058115</td>\n",
       "      <td>-0.087809</td>\n",
       "      <td>Feb</td>\n",
       "      <td>0.137472</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SC20</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.496547</td>\n",
       "      <td>-0.086107</td>\n",
       "      <td>Pave</td>\n",
       "      <td>0.700717</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.026216</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359882</td>\n",
       "      <td>-0.116501</td>\n",
       "      <td>-0.270606</td>\n",
       "      <td>-0.058115</td>\n",
       "      <td>-0.087809</td>\n",
       "      <td>May</td>\n",
       "      <td>-0.615009</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SC60</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.077742</td>\n",
       "      <td>0.081281</td>\n",
       "      <td>Pave</td>\n",
       "      <td>-1.028509</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.026216</td>\n",
       "      <td>Inside</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359882</td>\n",
       "      <td>-0.116501</td>\n",
       "      <td>-0.270606</td>\n",
       "      <td>-0.058115</td>\n",
       "      <td>-0.087809</td>\n",
       "      <td>Sep</td>\n",
       "      <td>0.137472</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SC70</td>\n",
       "      <td>RL</td>\n",
       "      <td>-0.460601</td>\n",
       "      <td>-0.091179</td>\n",
       "      <td>Pave</td>\n",
       "      <td>-1.028509</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.026216</td>\n",
       "      <td>Corner</td>\n",
       "      <td>...</td>\n",
       "      <td>4.086653</td>\n",
       "      <td>-0.116501</td>\n",
       "      <td>-0.270606</td>\n",
       "      <td>-0.058115</td>\n",
       "      <td>-0.087809</td>\n",
       "      <td>Feb</td>\n",
       "      <td>-1.367490</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SC60</td>\n",
       "      <td>RL</td>\n",
       "      <td>0.687976</td>\n",
       "      <td>0.386636</td>\n",
       "      <td>Pave</td>\n",
       "      <td>-1.028509</td>\n",
       "      <td>0.3047</td>\n",
       "      <td>0.026216</td>\n",
       "      <td>FR2</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.359882</td>\n",
       "      <td>-0.116501</td>\n",
       "      <td>-0.270606</td>\n",
       "      <td>-0.058115</td>\n",
       "      <td>-0.087809</td>\n",
       "      <td>Dec</td>\n",
       "      <td>0.137472</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id MSSubClass MSZoning  LotFrontage   LotArea Street  LotShape  \\\n",
       "0   1       SC60       RL    -0.221314 -0.202770   Pave  0.700717   \n",
       "1   2       SC20       RL     0.496547 -0.086107   Pave  0.700717   \n",
       "2   3       SC60       RL    -0.077742  0.081281   Pave -1.028509   \n",
       "3   4       SC70       RL    -0.460601 -0.091179   Pave -1.028509   \n",
       "4   5       SC60       RL     0.687976  0.386636   Pave -1.028509   \n",
       "\n",
       "   LandContour  Utilities LotConfig    ...      EnclosedPorch 3SsnPorch  \\\n",
       "0       0.3047   0.026216    Inside    ...          -0.359882 -0.116501   \n",
       "1       0.3047   0.026216       FR2    ...          -0.359882 -0.116501   \n",
       "2       0.3047   0.026216    Inside    ...          -0.359882 -0.116501   \n",
       "3       0.3047   0.026216    Corner    ...           4.086653 -0.116501   \n",
       "4       0.3047   0.026216       FR2    ...          -0.359882 -0.116501   \n",
       "\n",
       "  ScreenPorch  PoolArea   MiscVal MoSold    YrSold  SaleType  SaleCondition  \\\n",
       "0   -0.270606 -0.058115 -0.087809    Feb  0.137472        WD         Normal   \n",
       "1   -0.270606 -0.058115 -0.087809    May -0.615009        WD         Normal   \n",
       "2   -0.270606 -0.058115 -0.087809    Sep  0.137472        WD         Normal   \n",
       "3   -0.270606 -0.058115 -0.087809    Feb -1.367490        WD        Abnorml   \n",
       "4   -0.270606 -0.058115 -0.087809    Dec  0.137472        WD         Normal   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all numeric features\n",
    "numerical_features = []\n",
    "for feature in df.dtypes.index:\n",
    "    # Exclude the target variable 'SalePrice' and 'Id' column    \n",
    "    if (df[feature].dtype != np.object) and (str(df[feature].dtype) != 'category') and (feature != 'SalePrice') and (feature != 'Id') :\n",
    "        numerical_features.append(feature)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Again, from our combined df we get back our train & test datasets.\n",
    "train = df[:1456]\n",
    "test = df[1456:]\n",
    "\n",
    "train.loc[:,numerical_features] = scaler.fit_transform(train[numerical_features])\n",
    "test.loc[:,numerical_features] = scaler.transform(test[numerical_features])\n",
    "\n",
    "# Combine train and test so we can continue performing other operations on the whole dataset\n",
    "frames = [train, test]\n",
    "df = pd.concat(frames)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure there is no null value in the target feature\n",
    "np.where(np.isnan(df['SalePrice']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 One Hot Enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Norminal Variables\n",
    "\n",
    "MSZoning, Street, Alley, LotConfig, Neighborhood, Condition1, Condition2, BldgType, RoofStyle,\n",
    "HouseStyle,RoofMatl,Exterior1st,Exterior2nd,MasVnrType,Foundation,Heating, CentralAir, Electrical, GarageType\n",
    "PavedDrive, Fence, MiscFeature, SaleType, SaleCondition, Utilities,LandSlope\n",
    "\n",
    "'''\n",
    "category = ['MSZoning', 'Street',  'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'RoofStyle','HouseStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Foundation','Heating', 'CentralAir',  'GarageType', 'SaleType', 'SaleCondition','MSSubClass','MoSold']\n",
    "df_dummies = pd.get_dummies(df[category])\n",
    "df = df.drop(df[category],axis=1)\n",
    "df = pd.concat([df, df_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Log Transformation of target feature 'SalePrice'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\pandas\\core\\indexing.py:337: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n"
     ]
    }
   ],
   "source": [
    "# For the last time, from our combined df we get back our train & test datasets.\n",
    "train = df[:1456]\n",
    "test = df[1456:]\n",
    "\n",
    "# Since it contains zero values which we put initially for consistency sake, and we are done with all transformations, we can now drop it.\n",
    "test = test.drop(['SalePrice'],axis=1)\n",
    "\n",
    "# Log transformation of the target feature\n",
    "train.loc[:,'SalePriceLog'] = np.log(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. MODEL SELECTION & TRAINING \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train.drop(['SalePrice','SalePriceLog'],axis=1)\n",
    "y = train.SalePriceLog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Train Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision_tree [0.99999999448602372, 0.73322041865034138]\n",
      "KNN [0.65392473773323534, -0.54371163726170602]\n",
      "lm [0.94348033724576208, 0.89635697430574457]\n",
      "ridge [0.9428013749682832, 0.90778012886287451]\n",
      "random_forest [0.97705409127676335, 0.85361772460096363]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The Dataset for this project was split into half; train and test, with the test set\n",
    "not having the 'SalePrice' coulmn (target variable).\n",
    "So we are left with the first half to train the model on and use cross validaition\n",
    "to see how well each model performs.\n",
    "\n",
    "'''\n",
    "# Initialize different regression algorithms\n",
    "lm = linear_model.LinearRegression()\n",
    "Ridge = linear_model.Ridge()\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "random_forest = RandomForestRegressor()\n",
    "KNN = KNeighborsRegressor()\n",
    "\n",
    "models = [lm, ridge, decision_tree, random_forest,KNN]\n",
    "model_name = ['lm', 'ridge', 'decision_tree','random_forest','KNN']\n",
    "scorer = make_scorer(r2_score)\n",
    "result = {}\n",
    "\n",
    "for name, model in enumerate(models):\n",
    "    \n",
    "    model.fit(X,y)\n",
    "    train_score = model.score(X,y)\n",
    "    cv_score = cross_val_score(model, X, y,cv=3, scoring = scorer)\n",
    "    name = model_name[name]\n",
    "    result[name] = [train_score,cv_score.mean()]\n",
    "\n",
    "for model_scores in result:\n",
    "    print model_scores, result[model_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Model Selection and Hyperparameter tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Scores       | Linear Regression | Ridge             | Decision Tree     | Random Forest     | KNN               |\n",
    "|--------------|-------------------|-------------------|-------------------|-------------------|-------------------|\n",
    "| Train Score  |    0.94348        |    0.94280        |    0.99999        |    0.97388        |    0.65392        |\n",
    "| CV Score     |    0.89636        |    0.90778        |    0.72056        |    0.85411        |   -0.54371        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best alpha :', 10.0)\n",
      "Try again for more precision with alphas centered around 10.0\n",
      "('Best alpha :', 11.5)\n",
      "Root Mean squared error (Log): 0.09826\n",
      "0.938419191579\n"
     ]
    }
   ],
   "source": [
    "ridge = linear_model.RidgeCV(alphas = [ 0.1, 10, 20, 30])\n",
    "ridge.fit(X, y)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "\n",
    "print(\"Try again for more precision with alphas centered around \" + str(alpha))\n",
    "ridge = linear_model.RidgeCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, \n",
    "                          alpha * .9, alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15,\n",
    "                          alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4], cv = 10)\n",
    "ridge.fit(X, y)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha :\", alpha)\n",
    "train_prediction = ridge.predict(X)\n",
    "print(\"Root Mean squared error (Log): %.5f\" % log_rmse(ridge, X, y))\n",
    "print(ridge.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission(test,ridge,'ridge_submission')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
